{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"fomm-6c-sample-pro.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UfBYTZDqpu6y"},"source":["# Initialize training project"]},{"cell_type":"markdown","metadata":{"id":"dRO-DR88pl8-"},"source":["## Checking gpu in colab pro"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"3NaBJpMZxbr3","executionInfo":{"status":"ok","timestamp":1632776518161,"user_tz":300,"elapsed":2445,"user":{"displayName":"Jose Ysique Neciosup","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02109369839046454245"}},"outputId":"bb2b769d-0840-4464-c7eb-5375b29e0c48"},"source":["import torch\n","\n","torch.cuda.get_device_name(0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla P100-PCIE-16GB'"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"AZSy9NUorv5r"},"source":["## Entering the google drive data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FEMAIh7Ifa9s","executionInfo":{"status":"ok","timestamp":1632776540269,"user_tz":300,"elapsed":17966,"user":{"displayName":"Jose Ysique Neciosup","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02109369839046454245"}},"outputId":"75defb66-ea4a-4d54-ba65-533de5530d7e"},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"pk4-SHPOWEIu"},"source":["## Seeds for reproducibility\n"]},{"cell_type":"code","metadata":{"id":"q5ven54VJgzg"},"source":["%matplotlib inline\n","import numpy as np \n","import torch\n","import random\n","import os\n","from skimage import io, img_as_float32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"06tqtCEHWZ68"},"source":["def set_seed(seed):\n","  random.seed(seed)        \n","  torch.manual_seed(seed)  \n","\n","set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YC-_BIkaIBay"},"source":["## Partitioning on mini batches\n","<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/7C3SV7Q/sampling.jpg\" alt=\"sampling\" border=\"0\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"eLmACuiQrSnA"},"source":["Remember that this script was developed in a google collab context. You can change the path to the files in the ```data/vox-png``` folder.\n","\n","The ```batches.txt``` file is in charge of saving in numbers the indexes of files that will be used in each training group"]},{"cell_type":"code","metadata":{"id":"NN1x27yWmoa-"},"source":["main_path = '/content/drive/MyDrive/Tesis/first-order-model-6c/data/vox-png' #Cambiar la ruta de ser necesario\n","batch_index_path = '/content/drive/MyDrive/first-order-model-6c'\n","fbatches='batches.txt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X4yR-xedMhM1"},"source":["def directory_iter(files, batch_size, shuffle=True):\n","  n = files.shape[0]\n","  \n","  if shuffle:\n","    indices = np.random.permutation(n)\n","  else:\n","    indices = range(n)\n","\n","  for i in range(0, n, batch_size):\n","    batch_indices = indices[i:i+batch_size if i+batch_size <=n else n]\n","    #files_batch = files[batch_indices]\n","    yield batch_indices"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NwpOIVifMmBr"},"source":["We will save the indexes in the file ```batches.txt```"]},{"cell_type":"code","metadata":{"id":"USiYGTuVMmLh"},"source":["files=np.array(os.listdir(main_path))\n","batch_size = 400\n","total_samples = 0\n","mini_directory_bt=[]\n","\n","if os.path.isfile(os.path.join(batch_index_path,fbatches)):\n","  os.remove(os.path.join(batch_index_path,fbatches))\n","\n","with open(os.path.join(batch_index_path,fbatches), 'w') as f:\n","  for i, batch_indices in enumerate(directory_iter(files, batch_size), 1):\n","    total_samples += batch_indices.shape[0]\n","    #print(f'Batch {i} has size {batch_indices.shape[0]}') #To show the size of each lot\n","    for index in batch_indices:\n","      f.write(\"%s \" % index)\n","    f.write(\"\\n\")\n","\n","if total_samples == files.shape[0]:\n","  print(':) The total number of samples per batch is correct.')\n","else:\n","  print(':( The total number of samples per batch differs from the total number of samples.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ywys3N7GTSeV"},"source":["# TRAINING"]},{"cell_type":"markdown","metadata":{"id":"N5eufMp3tRsP"},"source":["Remember that this script was developed in a google collab context. You can change the path ```cd``` but in the same folder of the present model  **first-order-model-6c**"]},{"cell_type":"code","metadata":{"id":"9tqpBN-ZpFt-"},"source":["cd drive/MyDrive/Tesis/first-order-model-6c/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NGlk2iiOtO7g"},"source":["Installing First Order Model repository requirements"]},{"cell_type":"code","metadata":{"id":"xKG1ZZvQnk47"},"source":["#!pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-lfu-rg1oxJ"},"source":["from shutil import copy\n","import imageio\n","import numpy as np\n","import sys\n","import uuid\n","import yaml\n","import torch\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import warnings\n","from time import gmtime, strftime\n","from skimage import img_as_ubyte\n","from ctypes import cdll\n","from train import train\n","from modules.generator import OcclusionAwareGenerator\n","from modules.discriminator import MultiScaleDiscriminator\n","from modules.keypoint_detector import KPDetector\n","from frames_dataset import FramesDataset,FramesDatasetPartitioning\n","from modules.util import DownBlock2d\n","from tqdm import trange\n","from torch.utils.data import DataLoader\n","from logger import Logger\n","from modules.model import GeneratorFullModel, DiscriminatorFullModel\n","from torch.optim.lr_scheduler import MultiStepLR\n","from sync_batchnorm import DataParallelWithCallback\n","from frames_dataset import DatasetRepeater\n","#from demo import load_checkpoints, make_animation, load_checkpoints_Unet_3\n","from demo import load_checkpoints, make_animation"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SMzaIK1PtsDY"},"source":["Reading the ```batches.txt``` file and the **number of batch**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Kk3kfiA14rN","executionInfo":{"status":"ok","timestamp":1632791106585,"user_tz":300,"elapsed":665,"user":{"displayName":"Jose Ysique Neciosup","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02109369839046454245"}},"outputId":"02533a30-b2a6-4f75-fda2-5fb9e1784113"},"source":["num_batch=0\n","\n","batchf = './batches.txt'\n","config = './config/vox-adv-256.yaml'\n","\n","\n","batch_list=[]\n","with open(batchf, 'r') as f:\n","  for line in f.readlines():\n","    batch_list.append(list(map(int, line.rstrip().split(\" \"))))\n","\n","\n","with open(config) as f:\n","        config = yaml.load(f)\n","\n","dataset = FramesDatasetPartitioning(is_train=1, **config['dataset_params'],batches_list=batch_list[num_batch])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Use predefined train-test split.\n"]}]},{"cell_type":"markdown","metadata":{"id":"CW5RQPeMoqQp"},"source":["Debug the index file and the name of each video"]},{"cell_type":"code","metadata":{"id":"ReLLQGgM49aL"},"source":["print(batch_list[num_batch])\n","print(dataset.videos)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YnCHVWZzuGLg"},"source":["Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mfo7ApPT495K","executionInfo":{"status":"ok","timestamp":1632804909829,"user_tz":300,"elapsed":13795448,"user":{"displayName":"Jose Ysique Neciosup","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02109369839046454245"}},"outputId":"5a07a5ce-040a-409b-ba37-347610305975"},"source":["warnings.filterwarnings(\"ignore\")\n","\n","config = './config/vox-adv-256.yaml'\n","device_ids = [0]\n","#checkpoint = './models/vox-adv-cpk.pth.tar'\n","checkpoint = None\n","log_dir = './logs'\n","batchf= './batches.txt'\n","\n","\n","batch_list=[]\n","with open(batchf, 'r') as f:\n","  for line in f.readlines():\n","    batch_list.append(list(map(int, line.rstrip().split(\" \"))))\n","\n","if __name__ == \"__main__\":\n","    \n","    with open(config) as f:\n","        config = yaml.load(f)\n","        \n","    generator = OcclusionAwareGenerator(**config['model_params']['generator_params'], **config['model_params']['common_params'])\n","\n","    if torch.cuda.is_available():\n","        generator.to(device_ids[0])\n","\n","    discriminator = MultiScaleDiscriminator(**config['model_params']['discriminator_params'], **config['model_params']['common_params'])\n","\n","    if torch.cuda.is_available():\n","        discriminator.to(device_ids[0])\n","\n","    kp_detector = KPDetector(**config['model_params']['kp_detector_params'], **config['model_params']['common_params'])\n","\n","    if torch.cuda.is_available():\n","        kp_detector.to(device_ids[0])\n","            \n","    #dataset = FramesDatasetPartitioning(is_train=1, **config['dataset_params'],batches_list=batch_list[num_batch])\n","\n","    print(\"Training...\")\n","\n","    train_params = config['train_params']\n","\n","    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=train_params['lr_generator'], betas=(0.5, 0.999))\n","    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=train_params['lr_discriminator'], betas=(0.5, 0.999))\n","    optimizer_kp_detector = torch.optim.Adam(kp_detector.parameters(), lr=train_params['lr_kp_detector'], betas=(0.5, 0.999))\n","\n","    if checkpoint is not None:\n","        start_epoch = load_cpk(checkpoint, generator, discriminator, kp_detector, optimizer_generator, optimizer_discriminator, None if train_params['lr_kp_detector'] == 0 else optimizer_kp_detector)\n","    else:\n","        start_epoch = 0\n","\n","    scheduler_generator = MultiStepLR(optimizer_generator, train_params['epoch_milestones'], gamma=0.1, last_epoch=start_epoch - 1)\n","\n","    scheduler_discriminator = MultiStepLR(optimizer_discriminator, train_params['epoch_milestones'], gamma=0.1, last_epoch=start_epoch - 1)\n","\n","    scheduler_kp_detector = MultiStepLR(optimizer_kp_detector, train_params['epoch_milestones'], gamma=0.1, last_epoch=-1 + start_epoch * (train_params['lr_kp_detector'] != 0))\n","\n","    if 'num_repeats' in train_params or train_params['num_repeats'] != 1:\n","        dataset = DatasetRepeater(dataset, train_params['num_repeats'])\n","\n","    dataloader = DataLoader(dataset, batch_size=train_params['batch_size'], shuffle=True, num_workers=6, drop_last=True)\n","\n","    generator_full = GeneratorFullModel(kp_detector, generator, discriminator, train_params)\n","    discriminator_full = DiscriminatorFullModel(kp_detector, generator, discriminator, train_params)\n","\n","    if torch.cuda.is_available():\n","        generator_full = DataParallelWithCallback(generator_full, device_ids=device_ids)\n","        discriminator_full = DataParallelWithCallback(discriminator_full, device_ids=device_ids)\n","\n","    with Logger(log_dir=log_dir, visualizer_params=config['visualizer_params'], checkpoint_freq=train_params['checkpoint_freq']) as logger:\n","        for epoch in trange(start_epoch, train_params['num_epochs']):\n","            for x in dataloader:\n","                #print(dataloader)\n","                losses_generator, generated = generator_full(x)\n","\n","                loss_values = [val.mean() for val in losses_generator.values()]\n","                loss = sum(loss_values)\n","\n","                loss.backward()\n","                optimizer_generator.step()\n","                optimizer_generator.zero_grad()\n","                optimizer_kp_detector.step()\n","                optimizer_kp_detector.zero_grad()\n","\n","                if train_params['loss_weights']['generator_gan'] != 0:\n","                    optimizer_discriminator.zero_grad()\n","                    losses_discriminator = discriminator_full(x, generated)\n","                    loss_values = [val.mean() for val in losses_discriminator.values()]\n","                    loss = sum(loss_values)\n","\n","                    loss.backward()\n","                    optimizer_discriminator.step()\n","                    optimizer_discriminator.zero_grad()\n","                else:\n","                    losses_discriminator = {}\n","\n","                losses_generator.update(losses_discriminator)\n","                losses = {key: value.mean().detach().data.cpu().numpy() for key, value in losses_generator.items()}\n","                logger.log_iter(losses=losses)\n","\n","            scheduler_generator.step()\n","            scheduler_discriminator.step()\n","            scheduler_kp_detector.step()\n","            \n","            logger.log_epoch(epoch, {'generator': generator, 'discriminator': discriminator, 'kp_detector': kp_detector, 'optimizer_generator': optimizer_generator, 'optimizer_discriminator': optimizer_discriminator, 'optimizer_kp_detector': optimizer_kp_detector}, inp=x, out=generated)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [3:49:40<00:00, 1378.07s/it]\n"]}]},{"cell_type":"markdown","metadata":{"id":"OUmH3gW9TB9v"},"source":["# CHECKPOINT READING"]},{"cell_type":"markdown","metadata":{"id":"VnuXp9_mu1nA"},"source":["Showing the current training model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZRbPvAF4ip9","executionInfo":{"status":"ok","timestamp":1632805799001,"user_tz":300,"elapsed":2564,"user":{"displayName":"Jose Ysique Neciosup","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02109369839046454245"}},"outputId":"ce86ce52-d615-4dbf-8032-5d93e47a01e7"},"source":["checkpoint_path = './logs/00000009-checkpoint.pth.tar'\n","\n","config_path = './config/vox-adv-256.yaml'\n","generator1, kp_detector1 = load_checkpoints(config_path,checkpoint_path)\n","print(kp_detector1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DataParallelWithCallback(\n","  (module): KPDetector(\n","    (predictor): Hourglass(\n","      (encoder): Encoder(\n","        (down_blocks): ModuleList(\n","          (0): DownBlock2d(\n","            (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n","          )\n","          (1): DownBlock2d(\n","            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n","          )\n","          (2): DownBlock2d(\n","            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n","          )\n","          (3): DownBlock2d(\n","            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n","          )\n","          (4): DownBlock2d(\n","            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n","          )\n","          (5): DownBlock2d(\n","            (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n","          )\n","        )\n","      )\n","      (decoder): Decoder(\n","        (up_blocks): ModuleList(\n","          (0): UpBlock2d(\n","            (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): UpBlock2d(\n","            (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): UpBlock2d(\n","            (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): UpBlock2d(\n","            (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (4): UpBlock2d(\n","            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (5): UpBlock2d(\n","            (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (kp): Conv2d(35, 10, kernel_size=(7, 7), stride=(1, 1))\n","    (jacobian): Conv2d(35, 40, kernel_size=(7, 7), stride=(1, 1))\n","    (down): AntiAliasInterpolation2d()\n","  )\n",")\n"]}]},{"cell_type":"markdown","metadata":{"id":"6A2JrGCbTJfn"},"source":["# ANIMATION"]},{"cell_type":"markdown","metadata":{"id":"tvM4ofSuuPkg"},"source":["If we want a test of the model with the generated checkpoint, a source image and a driver video are saved"]},{"cell_type":"code","metadata":{"id":"6X4iH5BZTF3N"},"source":["from animate import normalize_kp\n","from skimage.transform import resize\n","from moviepy import editor\n","from tqdm import tqdm\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkR-WCpTTK41","executionInfo":{"status":"ok","timestamp":1632805861096,"user_tz":300,"elapsed":9891,"user":{"displayName":"Jose Ysique Neciosup","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02109369839046454245"}},"outputId":"33e77121-ce28-4153-afa7-ca0b7c89345f"},"source":["adapt_movement_scale = True \n","cpu = False\n","relative = True\n","\n","D_VIDEO_PATH = 'logs/animation/video_d.mp4'\n","S_IMAGE_PATH = 'logs/animation/image_s.png'\n","\n","G_VIDEO_PATH = 'logs/animation/video_g.mp4'\n","if os.path.isfile(G_VIDEO_PATH):\n","  os.remove(G_VIDEO_PATH)\n","\n","source_image = imageio.imread(S_IMAGE_PATH)\n","driving_video = imageio.mimread(D_VIDEO_PATH, memtest=False)\n","\n","reader = imageio.get_reader(D_VIDEO_PATH)\n","driving_video_FPS = reader.get_meta_data()['fps']\n","\n","source_image = resize(source_image, (256, 256))[..., :3]\n","driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n","driving_video_audio = editor.AudioFileClip(D_VIDEO_PATH)\n","\n","\n","with torch.no_grad():\n","  predictions = []\n","  source = torch.tensor(source_image[np.newaxis].astype(np.float32)).permute(0, 3, 1, 2)\n","  if not cpu:\n","    source = source.cuda()\n","    driving = torch.tensor(np.array(driving_video)[np.newaxis].astype(np.float32)).permute(0, 4, 1, 2, 3)\n","    kp_source = kp_detector1(source)\n","    kp_driving_initial = kp_detector1(driving[:, :, 0])\n","\n","    for frame_idx in tqdm(range(driving.shape[2])):\n","      percentage = (frame_idx + 1)/ driving.shape[2]\n","      #yield \"data:\" + str(percentage) + \"\\n\\n\"\n","      driving_frame = driving[:, :, frame_idx]\n","      if not cpu:\n","        driving_frame = driving_frame.cuda()\n","      kp_driving = kp_detector1(driving_frame)\n","      kp_norm = normalize_kp(kp_source=kp_source, kp_driving=kp_driving,\n","              kp_driving_initial=kp_driving_initial, use_relative_movement=relative,\n","              use_relative_jacobian=relative, adapt_movement_scale=adapt_movement_scale)\n","      out = generator1(source, kp_source=kp_source, kp_driving=kp_norm)\n","\n","      predictions.append(np.transpose(out['prediction'].data.cpu().numpy(), [0, 2, 3, 1])[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 150/150 [00:06<00:00, 22.27it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"Yvj4o7RKvAdg"},"source":["Saving de video generated"]},{"cell_type":"code","metadata":{"id":"6TWciTVJTNHH"},"source":["imageio.mimsave(G_VIDEO_PATH, [img_as_ubyte(frame) for frame in predictions], fps=driving_video_FPS)"],"execution_count":null,"outputs":[]}]}