{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fomm-unet3-sample-pro.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2be286860b3b4bb1afd94113ad247079":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6cb1b85fdf824244a1ee9008325e3a6e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3ab047042fdb4e17ae5d5fcfca09e88f","IPY_MODEL_b776392bde564c328eaec31de1a9adcc","IPY_MODEL_90f62283020b4fdc8017ea34b0047f78"]}},"6cb1b85fdf824244a1ee9008325e3a6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3ab047042fdb4e17ae5d5fcfca09e88f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8e7661f2dc104ee3b5791002ba0d077c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_80761fce4f054896ab00dcef89b835d8"}},"b776392bde564c328eaec31de1a9adcc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_806b22ff8b7640e29c421aa6863f40e7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":574673361,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":574673361,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5de7be66bc464a69a4540e8844342c6d"}},"90f62283020b4fdc8017ea34b0047f78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6fa17b1c430d45dda623141ceb766fff","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 548M/548M [00:05&lt;00:00, 122MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0707510582614aa8b066d60f136e8faa"}},"8e7661f2dc104ee3b5791002ba0d077c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"80761fce4f054896ab00dcef89b835d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"806b22ff8b7640e29c421aa6863f40e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5de7be66bc464a69a4540e8844342c6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6fa17b1c430d45dda623141ceb766fff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0707510582614aa8b066d60f136e8faa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"8PHeD9KUdOhj"},"source":["# Initialize training project"]},{"cell_type":"markdown","metadata":{"id":"OPYtgUkGdQxs"},"source":["## Checking gpu in colab pro"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"3NaBJpMZxbr3","executionInfo":{"status":"ok","timestamp":1632842019711,"user_tz":300,"elapsed":2798,"user":{"displayName":"Jose Ysique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggq2d0aTsuhhPAWm4QooPAhUwKzz8igJp_uy6VnZQ=s64","userId":"14551698101115015151"}},"outputId":"9b07506f-8081-4017-d3e9-b0cf3175683c"},"source":["import torch\n","\n","torch.cuda.get_device_name(0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla P100-PCIE-16GB'"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"Ug8mxWMCdSXg"},"source":["## Entering the google drive data"]},{"cell_type":"code","metadata":{"id":"FEMAIh7Ifa9s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632842046292,"user_tz":300,"elapsed":19528,"user":{"displayName":"Jose Ysique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggq2d0aTsuhhPAWm4QooPAhUwKzz8igJp_uy6VnZQ=s64","userId":"14551698101115015151"}},"outputId":"580289a0-b116-4aef-eb43-14576d798cca"},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"pk4-SHPOWEIu"},"source":["## Seeds para reproducibilidad\n"]},{"cell_type":"code","metadata":{"id":"UFNmiX7p5LQm"},"source":["%matplotlib inline\n","import numpy as np \n","import torch\n","import random\n","import os\n","from skimage import io, img_as_float32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"06tqtCEHWZ68"},"source":["def set_seed(seed):\n","  random.seed(seed)        \n","  torch.manual_seed(seed)  \n","\n","set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jrOHc90udW6Y"},"source":["## Partitioning on mini batches\n","<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/7C3SV7Q/sampling.jpg\" alt=\"sampling\" border=\"0\"></a>"]},{"cell_type":"markdown","metadata":{"id":"TRL3CF0VdZAL"},"source":["Remember that this script was developed in a google collab context. You can change the path to the files in the ```data/vox-png``` folder.\n","\n","The ```batches.txt``` file is in charge of saving in numbers the indexes of files that will be used in each training group"]},{"cell_type":"code","metadata":{"id":"NN1x27yWmoa-"},"source":["main_path = '/content/drive/MyDrive/Tesis/first-order-model-unet3/data/vox-png/train' #Cambiar la ruta de ser necesario\n","batch_index_path = '/content/drive/MyDrive/Tesis/first-order-model-unet3'\n","fbatches='batches.txt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X4yR-xedMhM1"},"source":["def directory_iter(files, batch_size, shuffle=True):\n","  n = files.shape[0]\n","  \n","  if shuffle:\n","    indices = np.random.permutation(n)\n","  else:\n","    indices = range(n)\n","\n","  for i in range(0, n, batch_size):\n","    batch_indices = indices[i:i+batch_size if i+batch_size <=n else n]\n","    #files_batch = files[batch_indices]\n","    yield batch_indices"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NwpOIVifMmBr"},"source":["We will save the indexes in the file ```batches.txt```"]},{"cell_type":"code","metadata":{"id":"USiYGTuVMmLh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632495984902,"user_tz":300,"elapsed":35586,"user":{"displayName":"Jose Ysique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggq2d0aTsuhhPAWm4QooPAhUwKzz8igJp_uy6VnZQ=s64","userId":"14551698101115015151"}},"outputId":"8e98ef36-82a9-4904-825c-a26e794e30b1"},"source":["files=np.array(os.listdir(main_path))\n","batch_size = 400\n","total_samples = 0\n","mini_directory_bt=[]\n","\n","if os.path.isfile(os.path.join(batch_index_path,fbatches)):\n","  os.remove(os.path.join(batch_index_path,fbatches))\n","\n","with open(os.path.join(batch_index_path,fbatches), 'w') as f:\n","  for i, batch_indices in enumerate(directory_iter(files, batch_size), 1):\n","    total_samples += batch_indices.shape[0]\n","    #print(f'Lote {i} tiene tamaño {batch_indices.shape[0]}')\n","    for index in batch_indices:\n","      f.write(\"%s \" % index)\n","    f.write(\"\\n\")\n","\n","if total_samples == files.shape[0]:\n","  print(':) El número total de muestras por lotes es correcto.')\n","else:\n","  print(':( El número total de muestras por lotes difiere del total de muestras.')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[":) El número total de muestras por lotes es correcto.\n"]}]},{"cell_type":"markdown","metadata":{"id":"A9xPEIns5SIn"},"source":["# TRAINING"]},{"cell_type":"markdown","metadata":{"id":"XtxHKHsWdjcg"},"source":["Remember that this script was developed in a google collab context. You can change the path ```cd``` but in the same folder of the present model  **first-order-model-unet3**"]},{"cell_type":"code","metadata":{"id":"9tqpBN-ZpFt-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632842064077,"user_tz":300,"elapsed":268,"user":{"displayName":"Jose Ysique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggq2d0aTsuhhPAWm4QooPAhUwKzz8igJp_uy6VnZQ=s64","userId":"14551698101115015151"}},"outputId":"ab911a9b-827d-4296-c384-b457edb48c61"},"source":["cd drive/MyDrive/Tesis/first-order-model-unet3/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Tesis/first-order-model-unet3\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZrFwStlNdm_5"},"source":["Installing First Order Model repository requirements"]},{"cell_type":"code","metadata":{"id":"6u7SWGJrdqNB"},"source":["#!pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-lfu-rg1oxJ"},"source":["from shutil import copy\n","import imageio\n","import numpy as np\n","import sys\n","import uuid\n","import yaml\n","import torch\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import warnings\n","from time import gmtime, strftime\n","from skimage import img_as_ubyte\n","from ctypes import cdll\n","from train import train\n","from modules.generator import OcclusionAwareGenerator\n","from modules.discriminator import MultiScaleDiscriminator\n","from modules.keypoint_detector import KPDetector_Unet_3\n","from frames_dataset import FramesDataset,FramesDatasetPartitioning\n","from modules.util import DownBlock2d\n","from tqdm import trange\n","from torch.utils.data import DataLoader\n","from logger import Logger\n","from modules.model import GeneratorFullModel, DiscriminatorFullModel\n","from torch.optim.lr_scheduler import MultiStepLR\n","from sync_batchnorm import DataParallelWithCallback\n","from frames_dataset import DatasetRepeater\n","#from demo import load_checkpoints, make_animation, load_checkpoints_Unet_3\n","from demo import load_checkpoints, make_animation"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IvhESbTHdvJX"},"source":["Reading the ```batches.txt``` file and the **number of batch**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Kk3kfiA14rN","executionInfo":{"status":"ok","timestamp":1632842165798,"user_tz":300,"elapsed":91061,"user":{"displayName":"Jose Ysique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggq2d0aTsuhhPAWm4QooPAhUwKzz8igJp_uy6VnZQ=s64","userId":"14551698101115015151"}},"outputId":"76f048ac-21a0-469a-a761-8291c649b480"},"source":["batchf = './batches.txt'\n","config = './config/vox-adv-256.yaml'\n","\n","num_batch=8\n","\n","batch_list=[]\n","with open(batchf, 'r') as f:\n","  for line in f.readlines():\n","    batch_list.append(list(map(int, line.rstrip().split(\" \"))))\n","\n","\n","with open(config) as f:\n","        config = yaml.load(f)\n","\n","dataset = FramesDatasetPartitioning(is_train=1, **config['dataset_params'],batches_list=batch_list[num_batch])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Use predefined train-test split.\n"]}]},{"cell_type":"markdown","metadata":{"id":"xx02xLlCdwh5"},"source":["Debug the index file and the name of each video"]},{"cell_type":"code","metadata":{"id":"ReLLQGgM49aL"},"source":["print(batch_list[num_batch])\n","print(dataset.videos)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gx6wszW3dyj5"},"source":["Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["2be286860b3b4bb1afd94113ad247079","6cb1b85fdf824244a1ee9008325e3a6e","3ab047042fdb4e17ae5d5fcfca09e88f","b776392bde564c328eaec31de1a9adcc","90f62283020b4fdc8017ea34b0047f78","8e7661f2dc104ee3b5791002ba0d077c","80761fce4f054896ab00dcef89b835d8","806b22ff8b7640e29c421aa6863f40e7","5de7be66bc464a69a4540e8844342c6d","6fa17b1c430d45dda623141ceb766fff","0707510582614aa8b066d60f136e8faa"]},"id":"Mfo7ApPT495K","executionInfo":{"status":"ok","timestamp":1632856686232,"user_tz":300,"elapsed":14520454,"user":{"displayName":"Jose Ysique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggq2d0aTsuhhPAWm4QooPAhUwKzz8igJp_uy6VnZQ=s64","userId":"14551698101115015151"}},"outputId":"fc07ae4c-d077-4683-bdf1-cc953fff3f97"},"source":["warnings.filterwarnings(\"ignore\")\n","\n","config = './config/vox-adv-256.yaml'\n","device_ids = [0]\n","#checkpoint = './models/vox-adv-cpk.pth.tar'\n","checkpoint = None\n","log_dir = './logs'\n","batchf= './batches.txt'\n","\n","batch_list=[]\n","'''\n","with open(batchf, 'r') as f:\n","  for line in f.readlines():\n","    batch_list.append(list(map(int, line.rstrip().split(\" \"))))\n","'''\n","if __name__ == \"__main__\":\n","    \n","    with open(config) as f:\n","        config = yaml.load(f)\n","        \n","    generator = OcclusionAwareGenerator(**config['model_params']['generator_params'], **config['model_params']['common_params'])\n","\n","    if torch.cuda.is_available():\n","        generator.to(device_ids[0])\n","\n","    discriminator = MultiScaleDiscriminator(**config['model_params']['discriminator_params'], **config['model_params']['common_params'])\n","\n","    if torch.cuda.is_available():\n","        discriminator.to(device_ids[0])\n","\n","    kp_detector = KPDetector_Unet_3(**config['model_params']['kp_detector_params'], **config['model_params']['common_params'])\n","\n","    if torch.cuda.is_available():\n","        kp_detector.to(device_ids[0])\n","            \n","    #dataset = FramesDatasetPartitioning(is_train=1, **config['dataset_params'],batches_list=batch_list[num_batch])\n","\n","    print(\"Training...\")\n","\n","    train_params = config['train_params']\n","\n","    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=train_params['lr_generator'], betas=(0.5, 0.999))\n","    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=train_params['lr_discriminator'], betas=(0.5, 0.999))\n","    optimizer_kp_detector = torch.optim.Adam(kp_detector.parameters(), lr=train_params['lr_kp_detector'], betas=(0.5, 0.999))\n","\n","    if checkpoint is not None:\n","        start_epoch = load_cpk(checkpoint, generator, discriminator, kp_detector, optimizer_generator, optimizer_discriminator, None if train_params['lr_kp_detector'] == 0 else optimizer_kp_detector)\n","    else:\n","        start_epoch = 0\n","\n","    scheduler_generator = MultiStepLR(optimizer_generator, train_params['epoch_milestones'], gamma=0.1, last_epoch=start_epoch - 1)\n","\n","    scheduler_discriminator = MultiStepLR(optimizer_discriminator, train_params['epoch_milestones'], gamma=0.1, last_epoch=start_epoch - 1)\n","\n","    scheduler_kp_detector = MultiStepLR(optimizer_kp_detector, train_params['epoch_milestones'], gamma=0.1, last_epoch=-1 + start_epoch * (train_params['lr_kp_detector'] != 0))\n","\n","    if 'num_repeats' in train_params or train_params['num_repeats'] != 1:\n","        dataset = DatasetRepeater(dataset, train_params['num_repeats'])\n","\n","    dataloader = DataLoader(dataset, batch_size=train_params['batch_size'], shuffle=True, num_workers=6, drop_last=True)\n","\n","    generator_full = GeneratorFullModel(kp_detector, generator, discriminator, train_params)\n","    discriminator_full = DiscriminatorFullModel(kp_detector, generator, discriminator, train_params)\n","\n","    if torch.cuda.is_available():\n","        generator_full = DataParallelWithCallback(generator_full, device_ids=device_ids)\n","        discriminator_full = DataParallelWithCallback(discriminator_full, device_ids=device_ids)\n","\n","    with Logger(log_dir=log_dir, visualizer_params=config['visualizer_params'], checkpoint_freq=train_params['checkpoint_freq']) as logger:\n","        for epoch in trange(start_epoch, train_params['num_epochs']):\n","            for x in dataloader:\n","                #print(dataloader)\n","                losses_generator, generated = generator_full(x)\n","\n","                loss_values = [val.mean() for val in losses_generator.values()]\n","                loss = sum(loss_values)\n","\n","                loss.backward()\n","                optimizer_generator.step()\n","                optimizer_generator.zero_grad()\n","                optimizer_kp_detector.step()\n","                optimizer_kp_detector.zero_grad()\n","\n","                if train_params['loss_weights']['generator_gan'] != 0:\n","                    optimizer_discriminator.zero_grad()\n","                    losses_discriminator = discriminator_full(x, generated)\n","                    loss_values = [val.mean() for val in losses_discriminator.values()]\n","                    loss = sum(loss_values)\n","\n","                    loss.backward()\n","                    optimizer_discriminator.step()\n","                    optimizer_discriminator.zero_grad()\n","                else:\n","                    losses_discriminator = {}\n","\n","                losses_generator.update(losses_discriminator)\n","                losses = {key: value.mean().detach().data.cpu().numpy() for key, value in losses_generator.items()}\n","                logger.log_iter(losses=losses)\n","\n","            scheduler_generator.step()\n","            scheduler_discriminator.step()\n","            scheduler_kp_detector.step()\n","            \n","            logger.log_epoch(epoch, {'generator': generator, 'discriminator': discriminator, 'kp_detector': kp_detector, 'optimizer_generator': optimizer_generator, 'optimizer_discriminator': optimizer_discriminator, 'optimizer_kp_detector': optimizer_kp_detector}, inp=x, out=generated)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2be286860b3b4bb1afd94113ad247079","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [4:01:41<00:00, 1450.13s/it]\n"]}]},{"cell_type":"markdown","metadata":{"id":"Fqboamj-1ttI"},"source":["# CHECKPOINT READING"]},{"cell_type":"code","metadata":{"id":"fHPYt54AqNvq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632856784982,"user_tz":300,"elapsed":2482,"user":{"displayName":"Jose Ysique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggq2d0aTsuhhPAWm4QooPAhUwKzz8igJp_uy6VnZQ=s64","userId":"14551698101115015151"}},"outputId":"a443870b-5c94-4756-a63a-d32aad02eeca"},"source":["checkpoint_path = './logs/00000009-checkpoint.pth.tar'\n","\n","config_path = './config/vox-adv-256.yaml'\n","generator1, kp_detector1 = load_checkpoints(config_path,checkpoint_path)\n","print(kp_detector1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DataParallelWithCallback(\n","  (module): KPDetector_Unet_3(\n","    (predictor): Unet_3_Plus(\n","      (encoder): Encoder_Unet_3(\n","        (down_blocks): ModuleList(\n","          (0): DownBlock2d_Unet_3(\n","            (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n","          )\n","          (1): DownBlock2d_Unet_3(\n","            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n","          )\n","          (2): DownBlock2d_Unet_3(\n","            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n","          )\n","          (3): DownBlock2d_Unet_3(\n","            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n","          )\n","          (4): DownBlock2d_Unet_3(\n","            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (norm): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n","          )\n","        )\n","      )\n","      (decoder): Decoder_Unet_3(\n","        (h1_PT_hd4): MaxPool2d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=True)\n","        (h1_PT_hd4_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (h1_PT_hd4_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (h1_PT_hd4_relu): ReLU(inplace=True)\n","        (h2_PT_hd4): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=True)\n","        (h2_PT_hd4_conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (h2_PT_hd4_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (h2_PT_hd4_relu): ReLU(inplace=True)\n","        (h3_PT_hd4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n","        (h3_PT_hd4_conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (h3_PT_hd4_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (h3_PT_hd4_relu): ReLU(inplace=True)\n","        (h4_Cat_hd4_conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (h4_Cat_hd4_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (h4_Cat_hd4_relu): ReLU(inplace=True)\n","        (hd5_UT_hd4): Upsample(scale_factor=2.0, mode=bilinear)\n","        (hd5_UT_hd4_conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (hd5_UT_hd4_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (hd5_UT_hd4_relu): ReLU(inplace=True)\n","        (conv4d_1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn4d_1): SynchronizedBatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu4d_1): ReLU(inplace=True)\n","        (h1_PT_hd3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=True)\n","        (h1_PT_hd3_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (h1_PT_hd3_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (h1_PT_hd3_relu): ReLU(inplace=True)\n","        (h2_PT_hd3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n","        (h2_PT_hd3_conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (h2_PT_hd3_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (h2_PT_hd3_relu): ReLU(inplace=True)\n","        (h3_Cat_hd3_conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (h3_Cat_hd3_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (h3_Cat_hd3_relu): ReLU(inplace=True)\n","        (hd4_UT_hd3): Upsample(scale_factor=2.0, mode=bilinear)\n","        (hd4_UT_hd3_conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (hd4_UT_hd3_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (hd4_UT_hd3_relu): ReLU(inplace=True)\n","        (hd5_UT_hd3): Upsample(scale_factor=4.0, mode=bilinear)\n","        (hd5_UT_hd3_conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (hd5_UT_hd3_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (hd5_UT_hd3_relu): ReLU(inplace=True)\n","        (conv3d_1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn3d_1): SynchronizedBatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu3d_1): ReLU(inplace=True)\n","        (h1_PT_hd2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n","        (h1_PT_hd2_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (h1_PT_hd2_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (h1_PT_hd2_relu): ReLU(inplace=True)\n","        (h2_Cat_hd2_conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (h2_Cat_hd2_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (h2_Cat_hd2_relu): ReLU(inplace=True)\n","        (hd3_UT_hd2): Upsample(scale_factor=2.0, mode=bilinear)\n","        (hd3_UT_hd2_conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (hd3_UT_hd2_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (hd3_UT_hd2_relu): ReLU(inplace=True)\n","        (hd4_UT_hd2): Upsample(scale_factor=4.0, mode=bilinear)\n","        (hd4_UT_hd2_conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (hd4_UT_hd2_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (hd4_UT_hd2_relu): ReLU(inplace=True)\n","        (hd5_UT_hd2): Upsample(scale_factor=8.0, mode=bilinear)\n","        (hd5_UT_hd2_conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (hd5_UT_hd2_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (hd5_UT_hd2_relu): ReLU(inplace=True)\n","        (conv2d_1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn2d_1): SynchronizedBatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2d_1): ReLU(inplace=True)\n","        (h1_Cat_hd1_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (h1_Cat_hd1_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (h1_Cat_hd1_relu): ReLU(inplace=True)\n","        (hd2_UT_hd1): Upsample(scale_factor=2.0, mode=bilinear)\n","        (hd2_UT_hd1_conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (hd2_UT_hd1_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (hd2_UT_hd1_relu): ReLU(inplace=True)\n","        (hd3_UT_hd1): Upsample(scale_factor=4.0, mode=bilinear)\n","        (hd3_UT_hd1_conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (hd3_UT_hd1_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (hd3_UT_hd1_relu): ReLU(inplace=True)\n","        (hd4_UT_hd1): Upsample(scale_factor=8.0, mode=bilinear)\n","        (hd4_UT_hd1_conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (hd4_UT_hd1_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (hd4_UT_hd1_relu): ReLU(inplace=True)\n","        (hd5_UT_hd1): Upsample(scale_factor=16.0, mode=bilinear)\n","        (hd5_UT_hd1_conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (hd5_UT_hd1_bn): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (hd5_UT_hd1_relu): ReLU(inplace=True)\n","        (conv1d_1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn1d_1): SynchronizedBatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1d_1): ReLU(inplace=True)\n","        (outconv1): Conv2d(320, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (kp): Conv2d(35, 10, kernel_size=(7, 7), stride=(1, 1))\n","    (jacobian): Conv2d(35, 40, kernel_size=(7, 7), stride=(1, 1))\n","    (down): AntiAliasInterpolation2d()\n","  )\n",")\n"]}]},{"cell_type":"markdown","metadata":{"id":"pZlKzvyb1yPB"},"source":["# ANIMATION"]},{"cell_type":"markdown","metadata":{"id":"eWHfluVhd7oY"},"source":["If we want a test of the model with the generated checkpoint, a source image and a driver video are saved"]},{"cell_type":"code","metadata":{"id":"WZHAsKLY12cd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632856787558,"user_tz":300,"elapsed":2581,"user":{"displayName":"Jose Ysique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggq2d0aTsuhhPAWm4QooPAhUwKzz8igJp_uy6VnZQ=s64","userId":"14551698101115015151"}},"outputId":"51b57c77-1413-4052-a612-16a24b84dba6"},"source":["from animate import normalize_kp\n","from skimage.transform import resize\n","from moviepy import editor\n","from tqdm import tqdm\n","import os"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n","Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n","Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2506752/45929032 bytes (5.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6070272/45929032 bytes (13.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b9617408/45929032 bytes (20.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12943360/45929032 bytes (28.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16424960/45929032 bytes (35.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19865600/45929032 bytes (43.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23552000/45929032 bytes (51.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27099136/45929032 bytes (59.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30646272/45929032 bytes (66.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b34127872/45929032 bytes (74.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37642240/45929032 bytes (82.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41115648/45929032 bytes (89.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b44621824/45929032 bytes (97.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n","  Done\n","File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"si27Kbkm122r","executionInfo":{"status":"ok","timestamp":1632856798507,"user_tz":300,"elapsed":10952,"user":{"displayName":"Jose Ysique","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggq2d0aTsuhhPAWm4QooPAhUwKzz8igJp_uy6VnZQ=s64","userId":"14551698101115015151"}},"outputId":"e77c5dce-d757-4969-c1a3-5aaae2d07afd"},"source":["adapt_movement_scale = True \n","cpu = False\n","relative = True\n","\n","D_VIDEO_PATH = 'logs/animation/video_d.mp4'\n","S_IMAGE_PATH = 'logs/animation/image_s.png'\n","\n","G_VIDEO_PATH = 'logs/animation/video_g.mp4'\n","if os.path.isfile(G_VIDEO_PATH):\n","  os.remove(G_VIDEO_PATH)\n","\n","source_image = imageio.imread(S_IMAGE_PATH)\n","driving_video = imageio.mimread(D_VIDEO_PATH, memtest=False)\n","\n","reader = imageio.get_reader(D_VIDEO_PATH)\n","driving_video_FPS = reader.get_meta_data()['fps']\n","\n","source_image = resize(source_image, (256, 256))[..., :3]\n","driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n","driving_video_audio = editor.AudioFileClip(D_VIDEO_PATH)\n","\n","\n","with torch.no_grad():\n","  predictions = []\n","  source = torch.tensor(source_image[np.newaxis].astype(np.float32)).permute(0, 3, 1, 2)\n","  if not cpu:\n","    source = source.cuda()\n","    driving = torch.tensor(np.array(driving_video)[np.newaxis].astype(np.float32)).permute(0, 4, 1, 2, 3)\n","    kp_source = kp_detector1(source)\n","    kp_driving_initial = kp_detector1(driving[:, :, 0])\n","\n","    for frame_idx in tqdm(range(driving.shape[2])):\n","      percentage = (frame_idx + 1)/ driving.shape[2]\n","      #yield \"data:\" + str(percentage) + \"\\n\\n\"\n","      driving_frame = driving[:, :, frame_idx]\n","      if not cpu:\n","        driving_frame = driving_frame.cuda()\n","      kp_driving = kp_detector1(driving_frame)\n","      kp_norm = normalize_kp(kp_source=kp_source, kp_driving=kp_driving,\n","              kp_driving_initial=kp_driving_initial, use_relative_movement=relative,\n","              use_relative_jacobian=relative, adapt_movement_scale=adapt_movement_scale)\n","      out = generator1(source, kp_source=kp_source, kp_driving=kp_norm)\n","\n","      predictions.append(np.transpose(out['prediction'].data.cpu().numpy(), [0, 2, 3, 1])[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 150/150 [00:07<00:00, 19.35it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"GGTvF_CRd9L2"},"source":["Saving de video generated"]},{"cell_type":"code","metadata":{"id":"8TgEx9p118L_"},"source":["imageio.mimsave(G_VIDEO_PATH, [img_as_ubyte(frame) for frame in predictions], fps=driving_video_FPS)"],"execution_count":null,"outputs":[]}]}